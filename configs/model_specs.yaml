# Model token limits for embedding and LLM. No hardcoded limits in code.
# Tokenizer must match model (OpenAI=tiktoken, HF=AutoTokenizer, Instructor=SentencePiece).

embedding_models:
  - name: "text-embedding-3-small"
    tokenizer_name: "cl100k_base"
    max_input_tokens: 8192

  - name: "text-embedding-3-large"
    tokenizer_name: "cl100k_base"
    max_input_tokens: 8192

llm_models:
  - name: "gpt-4o-mini"
    tokenizer_name: "cl100k_base"
    max_input_tokens: 128000
    max_output_tokens: 2048
    reserved_prompt_tokens: 1500

  - name: "gpt-4o"
    tokenizer_name: "cl100k_base"
    max_input_tokens: 128000
    max_output_tokens: 4096
    reserved_prompt_tokens: 2000
